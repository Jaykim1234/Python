{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03 Tutorial IMDB - NGram LM",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "75854de8d19b4a79b1af608a6aa228fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_293960821c4043a4ae37e19fb7907df6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0cfb747eb2984ac9aacf30e60b715645",
              "IPY_MODEL_350e7aa621d34d67a46c9a7d8582d2bb"
            ]
          }
        },
        "293960821c4043a4ae37e19fb7907df6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0cfb747eb2984ac9aacf30e60b715645": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_715979b0cb1340e58523aec1a4310ee3",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 100019,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100019,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7e8aff69d7df4cd69f06f5819d41d0b4"
          }
        },
        "350e7aa621d34d67a46c9a7d8582d2bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8510d385201d4d2dabb7acba259ae7d9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100019/100019 [02:47&lt;00:00, 597.98it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_79532d2f5beb4d7e98ef10ad73cb676b"
          }
        },
        "715979b0cb1340e58523aec1a4310ee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7e8aff69d7df4cd69f06f5819d41d0b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8510d385201d4d2dabb7acba259ae7d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "79532d2f5beb4d7e98ef10ad73cb676b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViSWXrxj0fA-"
      },
      "source": [
        "# Sentiment Analysis with N-Gram LM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sH5SkYKk0mF9"
      },
      "source": [
        "We are going to work with the [IMDB dataset](https://ai.stanford.edu/~amaas/data/sentiment/).\n",
        "\n",
        "Maas et al, (2011). \"Learning Word Vectors for Sentiment Analysis\"\n",
        "\n",
        "This is a collection of user generated movie reviews, each review being labelled as POSITIVE or NEGATIVE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYxGYv4f0_8U"
      },
      "source": [
        "# Download and Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZN-JfwWrvj_D"
      },
      "source": [
        "import requests\n",
        "\n",
        "r = requests.get('https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz')\n",
        "\n",
        "assert r.status_code == 200\n",
        "\n",
        "with open('imdb.tar.gz', 'wb') as out:\n",
        "    out.write(r.content)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lstqce5pwCma",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "75854de8d19b4a79b1af608a6aa228fa",
            "293960821c4043a4ae37e19fb7907df6",
            "0cfb747eb2984ac9aacf30e60b715645",
            "350e7aa621d34d67a46c9a7d8582d2bb",
            "715979b0cb1340e58523aec1a4310ee3",
            "7e8aff69d7df4cd69f06f5819d41d0b4",
            "8510d385201d4d2dabb7acba259ae7d9",
            "79532d2f5beb4d7e98ef10ad73cb676b"
          ]
        },
        "outputId": "539898fa-717d-4226-db69-40f96d627342"
      },
      "source": [
        "import tarfile\n",
        "import re\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "data = []\n",
        "filename = re.compile(r'aclImdb/(?P<split>train|test)/(?P<label>neg|pos)/(?P<id>[0-9_]+)\\.txt$')\n",
        "\n",
        "with tarfile.open('imdb.tar.gz', 'r:gz') as tgz:\n",
        "    for f in tqdm(tgz.getmembers()):\n",
        "        m = filename.match(f.name)\n",
        "        if f.isfile() and m is not None:\n",
        "            data.append({\n",
        "                'id': m['id'],\n",
        "                'split': m['split'],\n",
        "                'text': tgz.extractfile(f).read().decode('utf-8'),\n",
        "                'label': m['label']\n",
        "            })"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75854de8d19b4a79b1af608a6aa228fa",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=100019.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Jb_-eaMz8fD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "0a0354d1-3f6d-48e8-9e06-474cedd402ef"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>split</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>41984</th>\n",
              "      <td>4603_10</td>\n",
              "      <td>train</td>\n",
              "      <td>There is one detail, which is not very common ...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12156</th>\n",
              "      <td>12035_1</td>\n",
              "      <td>test</td>\n",
              "      <td>This movie made me so angry!! Here I am thinki...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3165</th>\n",
              "      <td>3106_1</td>\n",
              "      <td>test</td>\n",
              "      <td>Yeah, that's right. If I were to ask my friend...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26107</th>\n",
              "      <td>1068_1</td>\n",
              "      <td>train</td>\n",
              "      <td>My wife and I just finished this movie and I c...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24632</th>\n",
              "      <td>12059_10</td>\n",
              "      <td>test</td>\n",
              "      <td>I haven't seen this funny of a show on fox in ...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16974</th>\n",
              "      <td>4357_10</td>\n",
              "      <td>test</td>\n",
              "      <td>With documentary films, the question of realis...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11701</th>\n",
              "      <td>11722_4</td>\n",
              "      <td>test</td>\n",
              "      <td>I saw this film for one reason: the tagline is...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41309</th>\n",
              "      <td>3742_9</td>\n",
              "      <td>train</td>\n",
              "      <td>I thoroughly enjoyed this movie, but it is not...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37684</th>\n",
              "      <td>199_10</td>\n",
              "      <td>train</td>\n",
              "      <td>I've seen hundreds of silent movies. Some will...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26728</th>\n",
              "      <td>1727_3</td>\n",
              "      <td>train</td>\n",
              "      <td>We have a lake. We have an animated meteor cra...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             id  split                                               text label\n",
              "41984   4603_10  train  There is one detail, which is not very common ...   pos\n",
              "12156   12035_1   test  This movie made me so angry!! Here I am thinki...   neg\n",
              "3165     3106_1   test  Yeah, that's right. If I were to ask my friend...   neg\n",
              "26107    1068_1  train  My wife and I just finished this movie and I c...   neg\n",
              "24632  12059_10   test  I haven't seen this funny of a show on fox in ...   pos\n",
              "16974   4357_10   test  With documentary films, the question of realis...   pos\n",
              "11701   11722_4   test  I saw this film for one reason: the tagline is...   neg\n",
              "41309    3742_9  train  I thoroughly enjoyed this movie, but it is not...   pos\n",
              "37684    199_10  train  I've seen hundreds of silent movies. Some will...   pos\n",
              "26728    1727_3  train  We have a lake. We have an animated meteor cra...   neg"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFJ26rPX0ITa"
      },
      "source": [
        "train = df[df['split'] == 'train']\n",
        "\n",
        "test = df[df['split'] == 'test']\n",
        "X_test = test['text']\n",
        "y_test = test['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZmbsikW1C_o"
      },
      "source": [
        "# N-Gram LM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "comHK1da1FDa"
      },
      "source": [
        "We will use the Naive classifier as we have seen in class (see the [Notebook](https://colab.research.google.com/drive/1H9kWUGnI-LUVPvx0nfNvGdRWGeFtKdGT?usp=sharing))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KhNY1bSu4Lc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "465b52c1-5f11-4199-9a99-7baf4279a480"
      },
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXm13X9as4Kb"
      },
      "source": [
        "from nltk import ngrams\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trczmF3g1ZFP"
      },
      "source": [
        "Use the `ngrams` function instead of `bigrams` and `trigrams`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDYrX8hvum44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7a33e3e-47db-4a40-d853-149766d35344"
      },
      "source": [
        "list(ngrams(word_tokenize('I love Tokyo, it is so great to be there.'), n=4, pad_left=True, pad_right=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(None, None, None, 'I'),\n",
              " (None, None, 'I', 'love'),\n",
              " (None, 'I', 'love', 'Tokyo'),\n",
              " ('I', 'love', 'Tokyo', ','),\n",
              " ('love', 'Tokyo', ',', 'it'),\n",
              " ('Tokyo', ',', 'it', 'is'),\n",
              " (',', 'it', 'is', 'so'),\n",
              " ('it', 'is', 'so', 'great'),\n",
              " ('is', 'so', 'great', 'to'),\n",
              " ('so', 'great', 'to', 'be'),\n",
              " ('great', 'to', 'be', 'there'),\n",
              " ('to', 'be', 'there', '.'),\n",
              " ('be', 'there', '.', None),\n",
              " ('there', '.', None, None),\n",
              " ('.', None, None, None)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R5gWkWZ8FOy"
      },
      "source": [
        "def tokenizer(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    lower_tokens = list(map(lambda x: x.lower(), tokens))\n",
        "    return lower_tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDnpvs7Y1o8a"
      },
      "source": [
        "import math\n",
        "\n",
        "from collections import defaultdict\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "class NGramLM:\n",
        "    \"\"\"\n",
        "    Helper class to create and manipulate a N-Gram LM \n",
        "    \"\"\"\n",
        "    def __init__(self, label: str, ngram: int):\n",
        "        self.label = label\n",
        "        self.ngram = ngram\n",
        "\n",
        "    def fit(self, corpus):\n",
        "        \"\"\"\n",
        "        Assuming corpus is list of strings (['I love tea', 'NYC rules'])\n",
        "        \"\"\"\n",
        "        self.documents = corpus\n",
        "        \n",
        "        model = defaultdict(lambda: defaultdict(lambda: 1e-6))\n",
        " \n",
        "        for document in tqdm(self.documents, desc='Create Dictionary'):\n",
        "            # Consider only lowercase\n",
        "            tokens = tokenizer(document)\n",
        "            for ngram in ngrams(tokens, n=self.ngram, pad_right=True, pad_left=True):\n",
        "                model[ngram[:-1]][ngram[-1]] += 1\n",
        "\n",
        "        # Let's transform the counts to probabilities\n",
        "        for nminus1_gram in tqdm(model, desc='Update Probabilities'):\n",
        "            total_count = float(sum(model[nminus1_gram].values()))\n",
        "            for w in model[nminus1_gram]:\n",
        "                model[nminus1_gram][w] /= total_count\n",
        "\n",
        "        self.model = model\n",
        "    \n",
        "    def corpus_sample(self):\n",
        "        sample = random.choice(self.documents)\n",
        "\n",
        "        print(f'{colored(self.label, attrs=[\"bold\"])}')\n",
        "        print('*' * 80)\n",
        "        print(f'{colored(\"Original Data:\", color=\"blue\", attrs=[\"bold\"])}\\n{sample[:5]} (...)\\n(...) {sample[-5:]}')\n",
        "        print('*' * 80)\n",
        "        print(f'{colored(\"Full Text:\", color=\"blue\", attrs=[\"bold\"])}')\n",
        "        print(fill(' '.join(sample), width=80))\n",
        "        print(flush=True)\n",
        "\n",
        "    def compute_log_proba(self, txt):\n",
        "        prob = 0.0\n",
        "        for p in ngrams(tokenizer(txt), n=self.ngram, pad_right=True, pad_left=True):\n",
        "            prob += math.log(self.model[p[:-1]][p[-1]])\n",
        "        return prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UF2ZmvO0u14g"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class NaiveClassifier:\n",
        "    \"\"\"\n",
        "    Based on multiple N-Gram models.\n",
        "    \"\"\"\n",
        "    def __init__(self, models):\n",
        "        self.models = models\n",
        "\n",
        "    def predict(self, x):\n",
        "        predictions = []\n",
        "        for sample in tqdm(x):\n",
        "            probs = np.array([m.compute_log_proba(sample) for m in self.models])\n",
        "            prediction = self.models[np.argmax(probs)].label\n",
        "            predictions.append(prediction)\n",
        "        return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkU5aPR4A8f0"
      },
      "source": [
        "## TODO - N-GRAM LM / Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOMvW5d4A-LQ"
      },
      "source": [
        "* Use the class `NGramLM` to create a **3-Gram LM** based on the **POSITIVE** reviews of the **TRAIN** dataset.\n",
        "* POSITIVE means that `dataframe['label'] == 'pos'`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPhwgB2P8POK"
      },
      "source": [
        "pos_lm = NGramLM(\n",
        "    label='pos', \n",
        "    ngram= # TODO)\n",
        "\n",
        "pos_lm.fit(# TODO)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZ2omB4nBX1w"
      },
      "source": [
        "Show the probability distributions:\n",
        "* The first word in the sentence\n",
        "* Next word after `cinema was`\n",
        "* Next word after `what the`\n",
        "\n",
        "* Show the top 10 words after `what the`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12L2fye3DOBF"
      },
      "source": [
        "probs = pos_lm.model['what', 'the'].items()\n",
        "\n",
        "# probs is a list of tuple [('hello', 0.0012), ('cat', 0.0000001), ...]\n",
        "# each tuple is (word, probability)\n",
        "for x in sorted(probs, key=lambda x: x[1], reverse=True)[:10]:\n",
        "    print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhaDK017DgTl"
      },
      "source": [
        "Repeat the operations on the NEGATIVE reviews:\n",
        "* Use the class `NGramLM` to create a **3-Gram LM** based on the **NEGATIVE** reviews of the **TRAIN** dataset.\n",
        "* NEGATIVE means that `dataframe['label'] == 'neg'`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuraA0W-D3tA"
      },
      "source": [
        "neg_lm = NGramLM(\n",
        "    label='neg', \n",
        "    ngram= # TODO)\n",
        "\n",
        "neg_lm.fit(# TODO)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y_t2tYrD5ud"
      },
      "source": [
        "Show the probability distributions:\n",
        "* The first word in the sentence\n",
        "* Next word after `cinema was`\n",
        "* Next word after `what the`\n",
        "\n",
        "* Show the top 10 words after `what the`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KS5FDkmrD8zO"
      },
      "source": [
        "probs = neg_lm.model['what', 'the'].items()\n",
        "\n",
        "# probs is a list of tuple [('hello', 0.0012), ('cat', 0.0000001), ...]\n",
        "# each tuple is (word, probability)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnD-vyLNEAfo"
      },
      "source": [
        "Do the Classification:\n",
        "* Create the NaiveClassifier\n",
        "* Predict the classification for the **TEST** dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRau2DuC8-i1"
      },
      "source": [
        "clf = NaiveClassifier(# TODO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elkJuvfg-i4x"
      },
      "source": [
        "y_pred = clf.predict(# TODO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKi_mEJ0EUng"
      },
      "source": [
        "Produce the classification report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh603PC0-lgw"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(# TODO))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVOm_PmKEYeG"
      },
      "source": [
        "## TODO - GridSearch (Additional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cv1kBraGEi9O"
      },
      "source": [
        "Based on the code above:\n",
        "* Try the classification with different N (as in 3-Gram LM, 4-Gram LM, ...) (`N in [1, 2, 3, 4]` for example)\n",
        "* Plot the RECALL / PRECISION for POSITIVE / NEGATIVE reviews (4 plot lines)\n",
        "\n",
        "(hint: `classification_report(output_dict=True)` will return the data instead of generating a nice display)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxNDc0ZB_QUb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}