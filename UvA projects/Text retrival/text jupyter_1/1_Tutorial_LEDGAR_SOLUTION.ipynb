{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01 Tutorial LEDGAR - SOLUTION",
      "provenance": [],
      "collapsed_sections": [
        "lKgUNPzBKx6Z"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9dhzHMWsSF2"
      },
      "source": [
        "# Tutorial 1 - Legal Clause Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZjEfsllsXqG"
      },
      "source": [
        "Our corpus today is [LEDGAR](https://www.aclweb.org/anthology/2020.lrec-1.155.pdf), a dataset proposed in 2020 by Tuggener et al.\n",
        "\n",
        "Each document is a provision from an actual contract, written in English.\n",
        "\n",
        "A typical task of automatic discovery of contracts is the labeling of each provision. Today, we will build a classifier that can predict the label of a legal provision."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKgUNPzBKx6Z"
      },
      "source": [
        "# Pre-Requisites\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXpo6bOoK0qY"
      },
      "source": [
        "* Machine Learning: \n",
        "   * `sklearn` LogisticRegression, Pipeline, GridSearchCV\n",
        "   * Train / Test split, Cross-Validation\n",
        "* Text Vectorization\n",
        "   * Count Vectorizer parameters\n",
        "   * Vocabulary\n",
        "   * Stop Words\n",
        "* Useful modules\n",
        "   * pandas\n",
        "   * numpy\n",
        "   * matplotlib\n",
        "* Platform\n",
        "   * Colab has the advantage that the downloads are quite fast, and it comes with a good amount of RAM\n",
        "   * BUT it gives only 1 CPU, so computations can be slow, and parallelism will not improve\n",
        "   * If you use your own instance of Notebook on your laptop, the download might take more time, consider this and **download in advance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFVqj8oXtXiX"
      },
      "source": [
        "# Download"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2Y38o8OO648"
      },
      "source": [
        "If you run this Notebook on your computer, using Jupyter Notebook, instead of Google Colab, then download it on your own:\n",
        "* Here is the [Download Page](https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A)\n",
        "* Select `LEDGAR_2016-2019_clean.jsonl.zip`\n",
        "* Download it to your disk\n",
        "* Unzip it: it will create a file named `LEDGAR_2016-2019_clean.jsonl`\n",
        "* Skip the next 2 cells\n",
        "* Adjust the path\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq5nGku9sisO"
      },
      "source": [
        "!curl --header 'Host: drive.switch.ch' --user-agent 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:83.0) Gecko/20100101 Firefox/83.0' --header 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8' --header 'Accept-Language: en-US,en;q=0.5' --header 'DNT: 1' --referer 'https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A' --cookie 'oc641cdd42e0=13fa9330b2ce3965b18f77fa775559a5; oc_sessionPassphrase=R8jPmBjCrGkdXvI6wU%2FsMQZUqXCizggT9Aeafu3cvoXN671zkATnNRIQDSPQ4wnI7DuS6BRugjqGEjXOASVujRWxtO8BFm%2B56mMQBKUPMPucLCzrehfVBGyP0i06dh9c' --header 'Upgrade-Insecure-Requests: 1' 'https://drive.switch.ch/index.php/s/j9S0GRMAbGZKa1A/download?path=%2F&files=LEDGAR_2016-2019_clean.jsonl.zip&downloadStartSecret=038u1w43io1e' --output 'LEDGAR_2016-2019_clean.jsonl.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxALqM38slEA"
      },
      "source": [
        "!unzip LEDGAR_2016-2019_clean.jsonl.zip -d /tmp/LEDGAR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Q-Y3bnqLco4"
      },
      "source": [
        "# Import and Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qdglr50auyPe"
      },
      "source": [
        "import json\n",
        "data = [json.loads(line) for line in open('/tmp/LEDGAR/LEDGAR_2016-2019_clean.jsonl')]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oEvFCgGvh1b"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(data)\n",
        "df = df.drop(columns=['source'])\n",
        "print(f'Shape: {df.shape}')\n",
        "print(f'Columns: {df.columns}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2Ms_vYpxfha"
      },
      "source": [
        "df.sample(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GFRjlMGx5Jt"
      },
      "source": [
        "type(df.iloc[0]['label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7OmBhakyFet"
      },
      "source": [
        "df['nb_labels'] = df['label'].apply(len)\n",
        "print(df['nb_labels'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3u0YSBbLfmk"
      },
      "source": [
        "With 6 classes, we can have test results that are not `1.0`. While most of them are still `> 0.9`.\n",
        "\n",
        "You can try going even higher. It will slow down the LogisticRegression and the Pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mVsiyz02RVG"
      },
      "source": [
        "FOCUS_ON_TOP_N = 6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMWL5k9IbvZj"
      },
      "source": [
        "all_labels = [x for ls in df['label'] for x in ls]\n",
        "proto_labels = pd.Series(all_labels).value_counts()[:FOCUS_ON_TOP_N].index\n",
        "print(proto_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xY-9rXgUxWW2"
      },
      "source": [
        "focus = df[df['label'].apply(lambda x: any((z in x for z in proto_labels)))]\n",
        "print(focus.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k97mdSOScpV8"
      },
      "source": [
        "def select_label(list_labels):\n",
        "    for x in proto_labels:\n",
        "        try:\n",
        "            idx = list_labels.index(x)\n",
        "            return list_labels[idx]\n",
        "        except ValueError:\n",
        "            continue\n",
        "   \n",
        "    raise ValueError\n",
        "\n",
        "y = focus['label'].apply(select_label)\n",
        "X = focus['provision']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-RI21wuoG-b"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ud3PF53mLMxC"
      },
      "source": [
        "# Vectorizer and Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J26Vus_ovj1I"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(\n",
        "    stop_words='english',\n",
        "    min_df=3,\n",
        "    max_df=0.9\n",
        ")\n",
        "X_train_bow = vectorizer.fit_transform(X_train)\n",
        "X_test_bow = vectorizer.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKUxkP4Cvl7u"
      },
      "source": [
        "# Which words\n",
        "words = vectorizer.get_feature_names()\n",
        "\n",
        "print(f'Vocabulary size: {len(words)}')\n",
        "one_every_1000 = '\\n'.join(words[::1000])\n",
        "print(f'Sample:\\n{one_every_1000}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UjoYjf2e8sb"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = LogisticRegression(max_iter=1e4).fit(X_train_bow, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_cHDawCgAlr"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true=y_test, y_pred=clf.predict(X_test_bow)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1UuRkCHLRVV"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9KRbVoNsD7c"
      },
      "source": [
        "print(clf.coef_.shape)\n",
        "print(f'Nb Classes: {clf.coef_.shape[0]}, Nb Words: {clf.coef_.shape[1]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbF-0i5AsjS5"
      },
      "source": [
        "import numpy as np\n",
        "coefs = pd.DataFrame([{'class': clf.classes_[i], 'word': words[j], 'coef': co} for (i, j), co in np.ndenumerate(clf.coef_)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuxpRkwTt-9S"
      },
      "source": [
        "coefs.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDnfJkaYujx4"
      },
      "source": [
        "sort_by_coef = coefs.groupby(['class']).apply(lambda x: x.sort_values('coef', ascending=False)).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x16_oikwwY7C"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axs = plt.subplots(nrows=3, ncols=2, figsize=(20, 30))\n",
        "\n",
        "cut = 10\n",
        "\n",
        "for ((_, _), ax), (c, g) in zip(np.ndenumerate(axs), sort_by_coef.groupby('class')):\n",
        "    t_cut = g.head(cut)\n",
        "    ax.bar(x=range(cut), height=t_cut['coef'])\n",
        "    ax.set_xticks(range(cut))\n",
        "    ax.set_xticklabels(t_cut['word'], rotation=45, ha='right')\n",
        "    ax.set_title(c)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7xhT7RCgdFx"
      },
      "source": [
        "# Grid Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDCVcMvFKYIF"
      },
      "source": [
        "We consider a pipeline with 2 stages:\n",
        "* Vectorizer (IN: text, OUT: bag of words = vectors)\n",
        "* Classifier (IN: vectors, OUT: predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eBLDTkRGAR8"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('vect', CountVectorizer(stop_words='english')),\n",
        "    ('logreg', LogisticRegression(solver='sag', multi_class='multinomial', penalty='l2'))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOa8pvPsGh8S"
      },
      "source": [
        "parameters = {\n",
        "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
        "    'vect__max_features': (None, 5000),\n",
        "    'logreg__C': np.logspace(-2, 2, num=5)\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCZVFiEuIsw0"
      },
      "source": [
        "Warning, this will take quite some time !! \n",
        "\n",
        "* Expect 20 minutes on Google Colab\n",
        "* If you run on your own laptop, adjust `n_jobs=-1` below\n",
        "* There are ConvergenceWarning messages. If you are patient enough, adjust `max_iter=1e4` above, after `penalty='l2'`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbR2iFaIG4pO"
      },
      "source": [
        "grid = GridSearchCV(pipe, parameters, n_jobs=1, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPda60m-MAC3"
      },
      "source": [
        "grid.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68m6rg-_HW50"
      },
      "source": [
        "print(grid.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FL_tLuKJ1am"
      },
      "source": [
        "print(grid.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BID5OZOTJ3TF"
      },
      "source": [
        "grid.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVUW0LzQJ-CZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}